{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import CarotidDataset\n",
    "from unet import UNet\n",
    "from utils import DiceLoss, load_config\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'unet_3'\n",
    "config_path='./config/'\n",
    "config_file=f'{MODEL}.yaml'\n",
    "config = load_config(config_file, config_path)\n",
    "batch_size = 1\n",
    "data = CarotidDataset(crop=False)\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "_, _, test_data = torch.utils.data.random_split(data, [0.8, 0.1, 0.1], generator=generator)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    test_data, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=1)\n",
    "\n",
    "inputs, labels = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
